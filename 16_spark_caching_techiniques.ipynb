{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "00f53c9f-02db-46fc-8c0b-fbadfbb4d6e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.36:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Understand Caching</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x15a66ff80>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName(\"Understand Caching\")\n",
    "    .master(\"local[*]\")\n",
    "    .config(\"spark.executor.memory\", \"512M\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "936b3034-f2f7-4659-b48d-2fef840fb95c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- job_title: string (nullable = true)\n",
      " |-- salary: string (nullable = true)\n",
      "\n",
      "+----------+----------+--------------------+------+\n",
      "|first_name| last_name|           job_title|salary|\n",
      "+----------+----------+--------------------+------+\n",
      "|   Richard|  Morrison|Public relations ...|512653|\n",
      "|     Bobby|  Mccarthy|   Barrister's clerk|999836|\n",
      "|    Dennis|    Norman|Land/geomatics su...|131900|\n",
      "|      John|    Monroe|        Retail buyer|485506|\n",
      "|  Michelle|   Elliott|      Air cabin crew|604738|\n",
      "|    Ashley|   Montoya|        Cartographer|483339|\n",
      "| Nathaniel|     Smith|     Quality manager|419644|\n",
      "|     Faith|  Cummings|Industrial/produc...|205939|\n",
      "|  Margaret|    Sutton|Administrator, ed...|671167|\n",
      "|      Mary|    Sutton|   Freight forwarder|993829|\n",
      "|      Jake|      King|       Lexicographer|702101|\n",
      "|   Heather|     Haley|         Music tutor|570960|\n",
      "|    Thomas|    Thomas|Chartered managem...|339441|\n",
      "|   Leonard|   Carlson|       Art therapist|469728|\n",
      "|      Mark|      Wood|   Market researcher|582291|\n",
      "|    Tracey|Washington|Travel agency man...|146456|\n",
      "|   Rachael| Rodriguez|         Media buyer|544732|\n",
      "|      Tara|       Liu|   Financial adviser|399503|\n",
      "|       Ana|    Joseph|      Retail manager|761988|\n",
      "|   Richard|      Hall|Engineer, civil (...|660659|\n",
      "+----------+----------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read Sales CSV Data - 752MB Size ~ 7.2M Records\n",
    "# _schema = \"employee_id integer, department_id integer, name string, age integer, gender string, salary integer\"\n",
    "# df_emp = spark.read.format(\"csv\").option(\"header\", True).schema(_schema).load(\"data/input/emp.csv\")\n",
    "# df_emp.printSchema()\n",
    "# df_emp.show()\n",
    "\n",
    "df_emp = spark.read.format(\"csv\").option(\"header\", True).load(\"data/input/employee_records.csv\")\n",
    "df_emp1 = df_emp.select(\"first_name\", \"last_name\", \"job_title\", \"salary\")\n",
    "df_emp1.printSchema()\n",
    "df_emp1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4d652bbe-b549-4a5e-8987-ae132ab5c579",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "949640"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cache DataFrame (cache or persist)\n",
    "# default: deserialized, MEMORY_AND_DISK (for dataframe & dataset storage) \n",
    "# For RDD default caching is memory\n",
    "df_cache = df_emp1.where(\"salary > 60000\").cache() \n",
    "df_cache.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "db44e062-4ff6-40e7-8028-fc5c9a50105f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "959664"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emp1.where(\"salary > 50000\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "50262911-a314-4fbc-bf4c-1af78e089930",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/12 22:52:54 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.\n",
      "25/01/12 22:52:54 WARN BlockManager: Block rdd_63_7 replicated to only 0 peer(s) instead of 1 peers\n",
      "25/01/12 22:52:54 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.\n",
      "25/01/12 22:52:54 WARN BlockManager: Block rdd_63_1 replicated to only 0 peer(s) instead of 1 peers\n",
      "25/01/12 22:52:54 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.\n",
      "25/01/12 22:52:54 WARN BlockManager: Block rdd_63_3 replicated to only 0 peer(s) instead of 1 peers\n",
      "25/01/12 22:52:54 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.\n",
      "25/01/12 22:52:54 WARN BlockManager: Block rdd_63_0 replicated to only 0 peer(s) instead of 1 peers\n",
      "25/01/12 22:52:54 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.\n",
      "25/01/12 22:52:54 WARN BlockManager: Block rdd_63_6 replicated to only 0 peer(s) instead of 1 peers\n",
      "25/01/12 22:52:54 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.\n",
      "25/01/12 22:52:54 WARN BlockManager: Block rdd_63_4 replicated to only 0 peer(s) instead of 1 peers\n",
      "25/01/12 22:52:54 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.\n",
      "25/01/12 22:52:54 WARN BlockManager: Block rdd_63_5 replicated to only 0 peer(s) instead of 1 peers\n",
      "25/01/12 22:52:54 WARN RandomBlockReplicationPolicy: Expecting 1 replicas with only 0 peer/s.\n",
      "25/01/12 22:52:54 WARN BlockManager: Block rdd_63_2 replicated to only 0 peer(s) instead of 1 peers\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# MEMORY_ONLY, MEMORY_AND_DISK, MEMORY_ONLY_SER, MEMORY_AND_DISK_SER, DISK_ONLY, MEMORY_ONLY_2, MEMORY_AND_DISK_2\n",
    "import pyspark \n",
    "\n",
    "# df_persist = df_emp1.persist(pyspark.StorageLevel.MEMORY_ONLY) # Memory Serialized 1x Replicated\n",
    "df_persist = df_emp1.persist(pyspark.StorageLevel.MEMORY_ONLY_2) # Memory Serialized 2x Replicated\n",
    "df_persist.write.format(\"noop\").mode(\"overwrite\").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "10500d90-92cd-4d07-aa24-ef15b5964e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Cache\n",
    "# df_cache.unpersist()\n",
    "spark.catalog.clearCache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eb02199b-6ac9-4469-bd54-661906c06490",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb21696-06bc-49d6-a067-199e680060bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
