{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd186e0f-7f7d-4665-91e2-cab83a91f33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/01/26 21:37:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.34:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark SQL</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x107ef82c0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName(\"Spark SQL\")\n",
    "    .master(\"local[*]\")\n",
    "    .enableHiveSupport()\n",
    "    .config(\"spark.sql.warehouse.dir\", \"/data/output/spark-warehouse\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "814c3ecc-5b07-4211-a833-bd4ed4434cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+--------------------+----------+--------------------+------------------+--------+-------------+\n",
      "|first_name|last_name|           job_title|       dob|               email|             phone|  salary|department_id|\n",
      "+----------+---------+--------------------+----------+--------------------+------------------+--------+-------------+\n",
      "|   Richard| Morrison|Public relations ...|1973-05-05|melissagarcia@exa...|     (699)525-4827|512653.0|            8|\n",
      "|     Bobby| Mccarthy|   Barrister's clerk|1974-04-25|   llara@example.net|(750)846-1602x7458|999836.0|            7|\n",
      "|    Dennis|   Norman|Land/geomatics su...|1990-06-24| jturner@example.net|  873.820.0518x825|131900.0|           10|\n",
      "|      John|   Monroe|        Retail buyer|1968-06-16|  erik33@example.net|  820-813-0557x624|485506.0|            1|\n",
      "|  Michelle|  Elliott|      Air cabin crew|1975-03-31|tiffanyjohnston@e...|     (705)900-5337|604738.0|            8|\n",
      "+----------+---------+--------------------+----------+--------------------+------------------+--------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read Employee data\n",
    "_schema = \"first_name string, last_name string, job_title string, dob string, email string, phone string, salary double, department_id int\"\n",
    "\n",
    "emp = spark.read.format('csv').schema(_schema).option(\"header\", True).load(\"data/input/employee_records.csv\")\n",
    "\n",
    "emp.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "903c6c9e-2015-4221-9b11-4f6df2f0ceb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+--------------------+-------------+-----+-------------------+\n",
      "|department_id|     department_name|         description|         city|state|            country|\n",
      "+-------------+--------------------+--------------------+-------------+-----+-------------------+\n",
      "|            1|         Bryan-James|Optimized disinte...| Melissaburgh|   FM|Trinidad and Tobago|\n",
      "|            2|Smith, Craig and ...|Digitized empower...|   Morrisside|   DE|          Sri Lanka|\n",
      "|            3|Pittman, Hess and...|Multi-channeled c...|  North David|   SC|       Turkmenistan|\n",
      "|            4|Smith, Snyder and...|Reactive neutral ...|Lake Jennifer|   TX|         Madagascar|\n",
      "|            5|          Hardin Inc|Re-contextualized...|    Hayestown|   WA|               Fiji|\n",
      "+-------------+--------------------+--------------------+-------------+-----+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read DEPT CSV data\n",
    "\n",
    "_dept_schema = \"department_id string, department_name string, description string, city string, state string, country string\"\n",
    "\n",
    "dept = spark.read.format(\"csv\").schema(_dept_schema).option(\"header\", True).load(\"data/input/department_data.csv\")\n",
    "\n",
    "dept.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18c6ec87-8efb-436d-89ee-03065865e748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hive'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spark Catalog (Metadata) - in-memory/hive\n",
    "# without .enableHiveSupport() in sparkSession this config will return 'in-memory'\n",
    "\n",
    "spark.conf.get(\"spark.sql.catalogImplementation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "760cb158-5e8c-47ed-87de-739b19a8b80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/26 21:37:25 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "25/01/26 21:37:25 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "25/01/26 21:37:32 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0\n",
      "25/01/26 21:37:32 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore vrushabh.deokar@192.168.1.34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|  default|\n",
      "+---------+\n",
      "\n",
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "+---------+---------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/01/26 21:37:32 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException\n"
     ]
    }
   ],
   "source": [
    "# Show databases\n",
    "\n",
    "db = spark.sql(\"show databases\")\n",
    "db.show()\n",
    "\n",
    "spark.sql(\"show tables in default\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5faa3be2-e332-46f0-9ddf-60e71b4356c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "|         |dept_view|       true|\n",
      "|         | emp_view|       true|\n",
      "+---------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Register dataframes are temp views\n",
    "emp.createOrReplaceTempView(\"emp_view\")\n",
    "dept.createOrReplaceTempView(\"dept_view\")\n",
    "\n",
    "spark.sql(\"show tables in default\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b268d40-2116-42a1-b5b1-56103be724fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show tables/view in catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f855f60d-6d0f-4b41-9533-7cbf3b0cbc38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+--------------------+----------+--------------------+------------------+--------+-------------+\n",
      "|first_name|last_name|           job_title|       dob|               email|             phone|  salary|department_id|\n",
      "+----------+---------+--------------------+----------+--------------------+------------------+--------+-------------+\n",
      "|   Richard| Morrison|Public relations ...|1973-05-05|melissagarcia@exa...|     (699)525-4827|512653.0|            8|\n",
      "|     Bobby| Mccarthy|   Barrister's clerk|1974-04-25|   llara@example.net|(750)846-1602x7458|999836.0|            7|\n",
      "|    Dennis|   Norman|Land/geomatics su...|1990-06-24| jturner@example.net|  873.820.0518x825|131900.0|           10|\n",
      "|      John|   Monroe|        Retail buyer|1968-06-16|  erik33@example.net|  820-813-0557x624|485506.0|            1|\n",
      "|  Michelle|  Elliott|      Air cabin crew|1975-03-31|tiffanyjohnston@e...|     (705)900-5337|604738.0|            8|\n",
      "+----------+---------+--------------------+----------+--------------------+------------------+--------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View data from table\n",
    "\n",
    "emp_filtered = spark.sql(\"\"\"select * from emp_view\"\"\")\n",
    "emp_filtered.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28f68d08-7251-4467-9100-33fc78086737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+--------------------+-------------+-----+-------------------+\n",
      "|department_id|     department_name|         description|         city|state|            country|\n",
      "+-------------+--------------------+--------------------+-------------+-----+-------------------+\n",
      "|            1|         Bryan-James|Optimized disinte...| Melissaburgh|   FM|Trinidad and Tobago|\n",
      "|            2|Smith, Craig and ...|Digitized empower...|   Morrisside|   DE|          Sri Lanka|\n",
      "|            3|Pittman, Hess and...|Multi-channeled c...|  North David|   SC|       Turkmenistan|\n",
      "|            4|Smith, Snyder and...|Reactive neutral ...|Lake Jennifer|   TX|         Madagascar|\n",
      "|            5|          Hardin Inc|Re-contextualized...|    Hayestown|   WA|               Fiji|\n",
      "+-------------+--------------------+--------------------+-------------+-----+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View data from table\n",
    "\n",
    "dept_filtered = spark.sql(\"\"\"select * from dept_view\"\"\")\n",
    "dept_filtered.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b8e3f98-1c86-4a3d-9ab3-07a86742c331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column dob_year and register as temp view\n",
    "\n",
    "emp_temp = spark.sql(\"\"\"select e.*, date_format(dob, 'yyyy') as dob_year from emp_view e where department_id = 1\"\"\")\n",
    "emp_temp.createOrReplaceTempView(\"emp_temp_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba74be1e-18d4-4bde-a36b-51b3306b2292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+--------------------+----------+--------------------+------------------+--------+-------------+---------------+\n",
      "|first_name|last_name|           job_title|       dob|               email|             phone|  salary|department_id|department_name|\n",
      "+----------+---------+--------------------+----------+--------------------+------------------+--------+-------------+---------------+\n",
      "|   Richard| Morrison|Public relations ...|1973-05-05|melissagarcia@exa...|     (699)525-4827|512653.0|            8|     Parker PLC|\n",
      "|     Bobby| Mccarthy|   Barrister's clerk|1974-04-25|   llara@example.net|(750)846-1602x7458|999836.0|            7|    Ward-Gordon|\n",
      "|    Dennis|   Norman|Land/geomatics su...|1990-06-24| jturner@example.net|  873.820.0518x825|131900.0|           10| Delgado-Keller|\n",
      "|      John|   Monroe|        Retail buyer|1968-06-16|  erik33@example.net|  820-813-0557x624|485506.0|            1|    Bryan-James|\n",
      "|  Michelle|  Elliott|      Air cabin crew|1975-03-31|tiffanyjohnston@e...|     (705)900-5337|604738.0|            8|     Parker PLC|\n",
      "+----------+---------+--------------------+----------+--------------------+------------------+--------+-------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Join emp and dept - HINTs\n",
    "# Spark automatically do broadCast Join on smaller dataset\n",
    "\n",
    "emp_final = spark.sql(\"\"\"\n",
    "    select /*+ BROADCAST(d) */\n",
    "    e.* , d.department_name\n",
    "    from emp_view e left outer join dept_view d\n",
    "    on e.department_id = d.department_id\n",
    "\"\"\")\n",
    "\n",
    "emp_final.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9401d1cb-7171-45ae-89c1-d2a711bf7c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+--------------------+----------+--------------------+------------------+--------+-------------+---------------+\n",
      "|first_name|last_name|           job_title|       dob|               email|             phone|  salary|department_id|department_name|\n",
      "+----------+---------+--------------------+----------+--------------------+------------------+--------+-------------+---------------+\n",
      "|      John|   Monroe|        Retail buyer|1968-06-16|  erik33@example.net|  820-813-0557x624|485506.0|            1|    Bryan-James|\n",
      "|     Jacob|    Stark|         Fine artist|1976-04-25|jasonortiz@exampl...|224-695-9516x02171|358889.0|            1|    Bryan-James|\n",
      "|      Karl|     Kent|          Geochemist|1966-03-16|yjohnson@example.org|     (375)285-4892|717373.0|            1|    Bryan-James|\n",
      "|   Phillip|     Sims|Trading standards...|1979-04-03|jasonmarquez@exam...|      697.201.2204|326537.0|            1|    Bryan-James|\n",
      "|  Benjamin|   Norton| Art gallery manager|1976-12-06| debra86@example.com|   +1-936-375-8487|819473.0|            1|    Bryan-James|\n",
      "+----------+---------+--------------------+----------+--------------------+------------------+--------+-------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Join emp and dept - HINTs\n",
    "\n",
    "emp_final_1 = spark.sql(\"\"\"\n",
    "    select /*+ SHUFFLE_MERGE(e) */\n",
    "    e.* , d.department_name\n",
    "    from emp_view e left outer join dept_view d\n",
    "    on e.department_id = d.department_id\n",
    "\"\"\")\n",
    "\n",
    "emp_final_1.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b61ad887-99c9-4edc-8077-d96ab09ff93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show emp data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d29fe744-f571-4ca3-85f5-96f0222afd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the data as Table\n",
    "\n",
    "emp_final.write.format(\"parquet\").saveAsTable(\"emp_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8e30d25-e6d7-4114-89b5-3f9667353b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from Table\n",
    "\n",
    "emp_new = spark.sql(\"select * from emp_final\")\n",
    "emp_new.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9809c351-a499-489b-8daf-8f3ef2e2e8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persist metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5094b72-0c07-4a7e-8b23-db23aa1568db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------+-------+\n",
      "|       col_name|data_type|comment|\n",
      "+---------------+---------+-------+\n",
      "|  department_id|   string|   NULL|\n",
      "|department_name|   string|   NULL|\n",
      "|    description|   string|   NULL|\n",
      "|           city|   string|   NULL|\n",
      "|          state|   string|   NULL|\n",
      "|        country|   string|   NULL|\n",
      "+---------------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show details of metadata\n",
    "spark.sql(\"describe extended dept_view\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09cfe42c-017c-4551-ab25-6dc9dde5d59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f17a48-02bd-49ae-ae17-34b806608cce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
